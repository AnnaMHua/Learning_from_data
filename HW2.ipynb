{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoeffding Inequality\n",
    "Run a computer simulation for flipping 1,000 virtual fair coins. Flip each coin independently 10 times. Focus on 3 coins as follows: c1 is the first coin flipped, $c_{rand}$ is a coin chosen randomly from the 1,000, and $c_{min}$ is the coin which had the minimum frequency of heads (pick the earlier one in case of a tie). Let ν1, $ν_{rand}$, and $ν_{min}$ be the fraction of heads obtained for the 3 respective coins out of the 10 tosses. \n",
    "\n",
    "Run the experiment 100,000 times in order to get a full distribution of ν1, νrand, and νmin (note that crand and cmin will change from run to run)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The average value of νmin is closest to: \n",
    "\n",
    "[a] 0\n",
    "\n",
    "[b] 0.01 <---\n",
    "\n",
    "[c] 0.1\n",
    "\n",
    "[d] 0.5\n",
    "\n",
    "[e] 0.67\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class coin():\n",
    "    def __init__(self):\n",
    "        self.p = 0.5\n",
    "    \n",
    "    def flip(self):\n",
    "        val = random.random()\n",
    "        if val > self.p:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0380900000000018"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = []\n",
    "num_experiments=10000\n",
    "for j in range(num_experiments):\n",
    "    \n",
    "    num_flips = 10\n",
    "    all_coins = [coin() for x in range(1000)]\n",
    "    num_heads = []\n",
    "    for x in all_coins:\n",
    "        heads = 0\n",
    "        for i in range(num_flips):\n",
    "            if x.flip() ==1:\n",
    "                heads = heads+1\n",
    "        num_heads.append(heads)\n",
    "\n",
    "    c1 = all_coins[0]\n",
    "    ranindex = random.randint(0,999)\n",
    "    c_rand = all_coins[ranindex]\n",
    "    c_min = all_coins[num_heads.index(min(num_heads))]\n",
    "    v1 = num_heads[0]/num_flips\n",
    "    v_rand = num_heads[ranindex]/num_flips\n",
    "    v_min = num_heads[num_heads.index(min(num_heads))]/num_flips\n",
    "    v.append([v1,v_rand,v_min])\n",
    "    \n",
    "sum(np.transpose(v)[2])/num_experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Which coin(s) has a distribution of ν that satisfies the (single-bin) Hoeffding Inequality?\n",
    "\n",
    "[a] c1 only\n",
    "\n",
    "[b] crand only\n",
    "\n",
    "[c] cmin only\n",
    "\n",
    "[d] c1 and crand <--\n",
    "\n",
    "[e] cmin and crand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error and Noise\n",
    "\n",
    "Consider the bin model for a hypothesis h that makes an error with probability µ in approximating a deterministic target function f (both h and f are binary functions). If we use the same h to approximate a noisy version of f given by:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "P(y | x)=\\begin{cases}\n",
    "    \\lambda,& y = f(x)\\\\\n",
    "    1-\\lambda,              & y\\neq f(x)\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "3. What is the probability of error that h makes in approximating y? Hint: Two wrongs can make a right!\n",
    "\n",
    "[a] µ\n",
    "\n",
    "[b] λ\n",
    "\n",
    "[c] 1-µ\n",
    "\n",
    "[d] (1 − λ) ∗ µ + λ ∗ (1 − µ)\n",
    "\n",
    "[e] (1 − λ) ∗ (1 − µ) + λ ∗ µ **<---answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. At what value of λ will the performance of h be independent of µ?\n",
    "\n",
    "[a] 0\n",
    "\n",
    "[b] 0.5  **<--answer**\n",
    "\n",
    "[c] 1/√2\n",
    "\n",
    "[d] 1\n",
    "\n",
    "[e] No values of λ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "In these problems, we will explore how Linear Regression for classification works. As with the Perceptron Learning Algorithm in Homework # 1, you will create your own target function f and data set D. Take d = 2 so you can visualize the problem, and assume X = [−1, 1] × [−1, 1] with uniform probability of picking each x ∈ X . In each run, choose a random line in the plane as your target function f (do this by taking two random, uniformly distributed points in [−1, 1] × [−1, 1] and taking the line passing through them), where one side of the line maps to +1 and the other maps to −1. Choose the inputs xn of the data set as random points (uniformly in X ), and evaluate the target function on each xn to get the corresponding output yn.\n",
    "\n",
    "1. Take N = 100. Use Linear Regression to find g and evaluate Ein, the fraction of in-sample points which got classified incorrectly. Repeat the experiment 1000 times and take the average (keep the g’s as they will be used again in Problem 6). Which of the following values is closest to the average Ein? (Closest is the option that makes the expression |your answer −given option| closest to 0. Use this definition of closest here and throughout.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x1,x2):\n",
    "    return np.sign(x1-0.7*x2+0.6)\n",
    "\n",
    "def data(N):\n",
    "    temp = []\n",
    "    for i in range(N):\n",
    "        x1 = 2*random.random()-1\n",
    "        x2 = 2*random.random()-1\n",
    "        y = f(x1,x2) \n",
    "        temp.append([1,x1,x2,y])\n",
    "    return np.array(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(N):\n",
    "    test_data = data(N)\n",
    "    x = test_data[:,0:3]\n",
    "    y = te\n",
    "    w = np.linalg.solve(x.T@x,x.T@y)\n",
    "    #w = np.linalg.inv(x.T@x)@x.T@test_data[:,3]\n",
    "    error = 0\n",
    "    for i in range(N):\n",
    "        error = error + (np.sign(np.dot(w,x[i]))-test_data[i][3])**2\n",
    "    error = error/N\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-9237cf0ace15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-efa5f322db5d>\u001b[0m in \u001b[0;36mregression\u001b[0;34m(N)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#w = np.linalg.inv(x.T@x)@x.T@test_data[:,3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(1000):\n",
    "    sum = sum + regression(100)\n",
    "sum/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
